{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943e7775-31cf-43cf-95cb-77b18fe7f1d0",
   "metadata": {},
   "source": [
    "# Mapping US Census Tracts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fbf90-f29e-4920-88e6-1c073b57721c",
   "metadata": {},
   "source": [
    "With population density for every Census Tract in the US now tidily contained in one DataFrame, we can move on to the fun part - mapping! First we'll map the geometry of the Census Tracts, later we'll add color to visually represent population density. We'll be building a tile-map choropleth (as opposed to an outline-based choropleth.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e96a7-37ba-4b6f-94e5-73427bc0d2e2",
   "metadata": {},
   "source": [
    "Again, we've imported below the os and pathlib modules and included some code to make it easier to refer to the folders where our various data files are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f1dee3-8235-4fc9-8bc5-8fb19ae2952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os module provides a variety of frequently used file system functions including path.join\n",
    "# pathlib module makes it easier to manipulate folder and file paths with Python\n",
    "# everything builds off base_dir, so if we move our code later, we'll only need to change base_dir\n",
    "import os, pathlib\n",
    "# base_dir - the immediate parent folder of this notebook\n",
    "# we expect our data folders to be found here\n",
    "base_dir = pathlib.Path(os.getcwd()).parent\n",
    "\n",
    "# data_archive - we'll store compressed files here\n",
    "# these will be preserved in git\n",
    "data_archive_dir = os.path.join(base_dir, \"data_archive\")\n",
    "\n",
    "# data_dir - large/numerous files will go here\n",
    "# these will not be preserved in git!\n",
    "# we'll only put files here that can be recreated with some python code (e.g. downloaded \n",
    "# or unpacked from data_archive, or generated from a DataFrame)\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "\n",
    "# shapes_dir - folders containing shapefiles go here\n",
    "shapes_dir = os.path.join(data_dir,\"shapes\")\n",
    "\n",
    "# json_dir - we'll store here GeoJSON we've generated and want to save for re-use \n",
    "json_dir = os.path.join(data_dir,\"geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973af90f-05c3-4285-ae44-c0d2c0b8ba20",
   "metadata": {},
   "source": [
    "## Downloading NY State shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaaf148-4cca-45d9-b256-9f72d038818a",
   "metadata": {},
   "source": [
    "Now we can finally download our shapefiles! \n",
    "\n",
    "Source: ftp://ftp2.census.gov/geo/tiger/TIGER2020PL/LAYER/TRACT/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df985214-e623-4be1-8b75-ff8f710b0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the geopandas function read_file to grab our file\n",
    "import geopandas as gpd\n",
    "\n",
    "tract_shapefiles_dir = os.path.join(shapes_dir,\"tiger2020PL_NY_tracts\") # provide the full path for the directory containing our shapefiles\n",
    "ny_shapefiles=[x for x in pathlib.Path(tract_shapefiles_dir).iterdir() if x.is_file()] # make a list of all the files in the directory with their full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d93e6d-2269-4754-a402-96842d12c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block loops through our 'ny_shapefiles' list, and creates a separate list of FIPS codes for county and state \n",
    "county_codes=[] # create an empty list for County FIPS\n",
    "state_codes=[] # create an empty list for State FIPS\n",
    "filtered_shapefiles=[]\n",
    "for file in ny_shapefiles: \n",
    "    filename_parts = file.name.replace(\".zip\",\"\").split(\"_\") # take each filename - remove '.zip', split the remaining string wherever \"_\"  appears, and save it as a list\n",
    "    if len(filename_parts) >=3: # take every 'filename_parts' list containing 3 or more elements (fewer than 3 parts indicates a file is extraneous and we don't want it)\n",
    "        if len(filename_parts[2]) ==5: # take from each list the element at index 2 (position 3), but only if it contains 5 digits [State FIPS + County FIPS = 5 digits]\n",
    "            # filename_parts -->  tl_2020_36013_tract20.zip\n",
    "            # 36013 <---filename_parts[2]\n",
    "            # 013 <---filename_parts[2][1:4]\n",
    "            county_codes.append(filename_parts[2][-3:]) # take the last 3 digits of the element at index 2, and append it to the list \n",
    "            state_codes.append(filename_parts[2][0:2])  # take the first 3 digits of the element at index 2, State FIPS, and append it to our list\n",
    "            filtered_shapefiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e3abb6-0e2b-4256-b3d0-a9adbb1a8552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fae9a6-1842-49e1-8eb2-ee14f8b70190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d110ecd4-8967-4493-8d50-04b1fe60add1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m files_to_load \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(state_codes, county_codes, filtered_shapefiles))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# now let's turn it into a DataFrame and rename the columns for consistency\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df_ny_shapes \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(files_to_load)\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState FIPS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounty FIPS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile name\u001b[39m\u001b[38;5;124m'\u001b[39m}, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# df_ny_shapes = pd.DataFrame.from_records(files_to_load)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df_ny_shapes\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# lets zip our 3 lists into one and call it 'files_to_load'\n",
    "files_to_load = list(zip(state_codes, county_codes, filtered_shapefiles))\n",
    "\n",
    "\n",
    "# now let's turn it into a DataFrame and rename the columns for consistency\n",
    "df_ny_shapes = pd.DataFrame.from_records(files_to_load).rename({0: 'State FIPS', 1: 'County FIPS', 2: 'File name'}, axis=1)\n",
    "# df_ny_shapes = pd.DataFrame.from_records(files_to_load)\n",
    "df_ny_shapes\n",
    "\n",
    "# to ensure the dtypes of the State and County codes are correctly cast as integers, let's set them here\n",
    "df_ny_shapes['State FIPS'] = df_ny_shapes['State FIPS'].astype(int)\n",
    "df_ny_shapes['County FIPS'] = df_ny_shapes['County FIPS'].astype(int)\n",
    "df_ny_shapes.info()\n",
    "df_ny_shapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008f1c0-54f1-42e2-b300-6bd69ed421b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge our two DataFrames into one that contains just the counties within New York City and the full path to their shapefile\n",
    "df_ny = df_nyc_codes.merge(df_ny_shapes)\n",
    "df_ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18750d-443a-43ad-97c8-822c82512cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create a GEO DataFrame with just the columns we need and rename them for consistency\n",
    "import geopandas as gpd\n",
    "\n",
    "zipfile = os.path.join(shapes_dir, 'tiger2020PL_NY_tracts/tl_2020_36005_tract20.zip')\n",
    "geo_df = gpd.read_file(zipfile)[['STATEFP20','COUNTYFP20', 'TRACTCE20',\n",
    "                                 'GEOID20', 'ALAND20', 'geometry']].rename(\n",
    "                                    {'STATEFP20': 'State FIPS','COUNTYFP20': 'County FIPS', \n",
    "                                     'TRACTCE20': 'Census Tract', 'GEOID20': 'GEOID', 'ALAND20': 'Land Area'}, axis=1\n",
    "                                    )\n",
    "\n",
    "geo_df\n",
    "\n",
    "### this is the longer way of writing the above code\n",
    "#geo_df = gpd.read_file(zipfile)\n",
    "\n",
    "# geo_df['State FIPS'] = geo_df['State FIPS'].astype(int)\n",
    "# geo_df['County FIPS'] = geo_df['County FIPS'].astype(int)\n",
    "# geo_df['Census Tract'] = geo_df['Census Tract'].astype(int)\n",
    "# geo_df['GEOID'] = geo_df['GEOID'].astype(int)\n",
    "# geo_df\n",
    "# make a geo dataframe for each of the 5 counties\n",
    "# concatenate into one big DF and map it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946b12e-9ab6-45d4-995b-9388dd778370",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff922a96-6e00-4f73-8ab6-b576983ffdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "ny_map = KeplerGl(height=600, show_docs=False)\n",
    "for row in df_ny.itertuples():\n",
    "    zipfile = f\"zip://{row[7]}\"\n",
    "    ny_map.add_data(data=gpd.read_file(zipfile), name=row[5])\n",
    "ny_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4714bd0-347f-4451-bf0f-8139c9fc07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ny_map.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc9511-352c-4876-b85d-d9cc1828bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# 32mb+ of census data saved in a 4.7mb archive\n",
    "census_data_archive = os.path.join(data_archive_dir, \"census_data_2022_03_01.tgz\")\n",
    "\n",
    "# This is the US Census file with population data we will extract\n",
    "# this file is contained in the above tgz file\n",
    "census_2020_file = \"DECENNIALPL2020.P1_data_with_overlays_2021-12-02T121459.csv\"\n",
    "\n",
    "use_cols = [0, 1, 2]\n",
    "col_names = ['GEOID', 'CENSUS TRACT NAME', 'POPULATION']\n",
    "\n",
    "# This extracts a DataFrame from a tgz archived file\n",
    "def extract_from_tgz(filename):\n",
    "    with tarfile.open(filename) as tf:\n",
    "        for file in tf.getmembers():\n",
    "            if file.name == census_2020_file:\n",
    "                data = tf.extractfile(file)\n",
    "                return pd.read_csv(data, low_memory=False, skiprows=1, header=0, usecols=use_cols, names=col_names)\n",
    "\n",
    "df_census_raw = extract_from_tgz(census_data_archive)\n",
    "\n",
    "# change some options that determine how much data is displayed in the notebook\n",
    "\n",
    "\n",
    "df_census_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a94ea5-7056-4c0c-95f5-0970bc8f0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_fp = df_census_raw['GEOID'].str.slice(9,11).rename('State FIPS').astype(int)\n",
    "# county_fp = df_census_raw['GEOID'].str.slice(11,14).rename('County FIPS').astype(int)\n",
    "# df_census_pop = pd.concat([df_census_raw, state_fp, county_fp], axis=1).drop('GEOID', axis=1)\n",
    "# df_census_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd13eb-5bd5-4a7b-a890-b14c20ef9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_codes.merge(df_census_pop, on=['State FIPS', 'County FIPS'], how='inner')\n",
    "#df_codes.dtypes\n",
    "df_ny = df_ny_shapes.merge(df_all, on=['State FIPS', 'County FIPS'], how='inner')\n",
    "df_ny\n",
    "# This is probably not the dataframe we want\n",
    "# the rows are at a Census Tract Level of Granularity\n",
    "# but I merged in files... which are at a county level of granularity\n",
    "# .. we want to load the files for the counties we want.. ONCE...\n",
    "# so either... filter this list to the rows you want and then find\n",
    "# the \"unique\" list of filenames you want.... \n",
    "# see paragrap below this for an example... the county filenames\n",
    "# are repeated across all the census tracts for NY..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bd730-fd34-4c93-b1ec-b5294eec7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ny.loc[df_ny['Place'] == 'New York City']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcd5-f8df-4005-8630-5baf21ce2965",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "**Choropleth**\n",
    "A choropleth  is a map made of different colored polygons, where each color represents a different quantity or range of quantities. \n",
    "\n",
    "**Shapefile**\n",
    "A standardize file format for storing geospatial information, including geometry (coordinates) and attributes of geographic features, needed to create maps. \n",
    "\n",
    "**TIGER?**\n",
    "TIGER, also referred to as MAF/TIGER, is the Census Bureau's geographic database system. The acronym MAF/TIGER stands for Master Address. File/Topologically Integrated Geographic Encoding and Referencing. \n",
    "\n",
    "**GeoJSON** \n",
    "A format for storing a variety of geographic data and is based on JSON. We know that JSON is format for storing data. Similar to a Python dictionaries, it uses key value pairs. Dictionaries can be nested.\n",
    "\n",
    "**Which areas do the TIGER/Line shapefiles describe?**\n",
    "Shapefiles are available for the fifty states, District of Columbia, Puerto Rico, and the Island areas (American Samoa, the Commonwealth of the Northern\n",
    "Mariana Islands, Guam, and the United States Virgin Islands).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65508d3d-54ca-42c5-9bc1-08d0df1e790e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
