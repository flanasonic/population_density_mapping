{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf99b011-96b6-42d5-b117-511a3c83389b",
   "metadata": {},
   "source": [
    "## Mapping New York City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550cf87-f338-4538-8c63-e69ea164f762",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "\n",
    "*GIS*\n",
    "* **2020 Census Redistricting Data (P.L. 94-171) Shapefiles** - downloaded from the [ftp archive](https://www2.census.gov/geo/tiger/TIGER2020PL/LAYER/TRACT/2020/) via ftp client\n",
    "* To download just the files for NY State, selecting only files whose names begin with \"tl_2020_36\"\n",
    "* Data can also be downloaded through a browser, but may result in formatting issues, so I recommend avoiding this, is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa95a7d-cb90-4835-92cd-1f2743492428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "base_dir = pathlib.Path(os.getcwd()).parent\n",
    "data_archive_dir = os.path.join(base_dir, \"data_archive\")\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "shapes_dir = os.path.join(data_dir,\"shapes\")\n",
    "json_dir = os.path.join(data_dir,\"geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2668a220-2fb4-4c49-869c-9fc5e10746ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID Census Tract Full</th>\n",
       "      <th>Census Tract Name</th>\n",
       "      <th>Population</th>\n",
       "      <th>Census Tract Code</th>\n",
       "      <th>State FIPS</th>\n",
       "      <th>County FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US01001020100</td>\n",
       "      <td>Census Tract 201, Autauga County, Alabama</td>\n",
       "      <td>1775</td>\n",
       "      <td>020100</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US01001020200</td>\n",
       "      <td>Census Tract 202, Autauga County, Alabama</td>\n",
       "      <td>2055</td>\n",
       "      <td>020200</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GEOID Census Tract Full                          Census Tract Name  \\\n",
       "1    1400000US01001020100  Census Tract 201, Autauga County, Alabama   \n",
       "2    1400000US01001020200  Census Tract 202, Autauga County, Alabama   \n",
       "\n",
       "  Population Census Tract Code State FIPS County FIPS  \n",
       "1       1775            020100         01         001  \n",
       "2       2055            020200         01         001  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "file_census_data_tgz = os.path.join(data_archive_dir, 'census_data_2022_03_01.tgz')\n",
    "file_census_data_csv = 'DECENNIALPL2020.P1_data_with_overlays_2021-12-02T121459.csv'\n",
    "\n",
    "# this function creates a DataFrame from our tgz archive file\n",
    "def extract_from_tgz(filename):\n",
    "    with tarfile.open(filename) as tf:\n",
    "        for file in tf.getmembers():\n",
    "            if file.name == file_census_data_csv:\n",
    "                data = tf.extractfile(file)\n",
    "                return pd.read_csv(data, low_memory=False, usecols=[0, 1, 2])\n",
    "\n",
    "df_census = extract_from_tgz(file_census_data_tgz)\n",
    "df_census = df_census.drop(0)\n",
    "df_census.columns = [\"GEOID Census Tract Full\", \"Census Tract Name\", \"Population\"]\n",
    "df_census['Census Tract Code'] = df_census['GEOID Census Tract Full'].str.slice(-6)\n",
    "df_census['State FIPS'] = df_census['GEOID Census Tract Full'].str.slice(9,11)\n",
    "df_census['County FIPS'] = df_census['GEOID Census Tract Full'].str.slice(11,14)\n",
    "#df_census.dtypes\n",
    "df_census.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d638e973-3905-4718-b923-d74f04c75eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>State FIPS</th>\n",
       "      <th>Place</th>\n",
       "      <th>Place FIPS</th>\n",
       "      <th>County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Abanda CDP</td>\n",
       "      <td>100</td>\n",
       "      <td>Chambers County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Abbeville city</td>\n",
       "      <td>124</td>\n",
       "      <td>Henry County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Adamsville city</td>\n",
       "      <td>460</td>\n",
       "      <td>Jefferson County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  State FIPS            Place  Place FIPS            County\n",
       "0    AL           1       Abanda CDP         100   Chambers County\n",
       "1    AL           1   Abbeville city         124      Henry County\n",
       "2    AL           1  Adamsville city         460  Jefferson County"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_place = os.path.join(data_archive_dir, 'PLACElist.txt')\n",
    "\n",
    "df_place = pd.read_csv(file_place, \n",
    "                       delimiter=\"|\", \n",
    "                       usecols=['STATE', 'STATEFP', 'PLACEFP', 'PLACENAME', 'COUNTY'], # use only these columns\n",
    "                       encoding=\"iso-8859-1\" # QUESTION: Patrick, this txt file uses ANSI encoding, what should we use here?\n",
    "                       )[['STATE','STATEFP', 'PLACENAME', 'PLACEFP', 'COUNTY']] # reorder columns\n",
    "\n",
    "#encoding_errors='ignore'\n",
    "df_place.rename(columns={'STATE': 'State', 'STATEFP': 'State FIPS', 'PLACENAME': 'Place', 'PLACEFP': 'Place FIPS', 'COUNTY': 'County'}, inplace=True) # rename columns\n",
    "df_place.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6578110c-5f3b-47c7-8ed0-3f7acec27065",
   "metadata": {},
   "source": [
    "## Geographic Data\n",
    "\n",
    "The Census Bureau provides geographic this information in the form of shapefiles. We'll convert this to GeoJSON for mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dd8c3d-cf1d-4eba-9d5c-2bcc026420ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the geopandas function read_file to grab our file\n",
    "import geopandas as gpd\n",
    "# Julie download this file from here: /geo/tiger/TIGER2020PL/LAYER/PLACE/2020\n",
    "# this is a different file than Patrick is using\n",
    "shapefiles_dir_place = os.path.join(shapes_dir,\"tl_2020_36_place20.zip\")\n",
    "shape_place_df = gpd.read_file(shapefiles_dir_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84242a80-5b49-4a9d-be93-29a493de9abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State FIPS</th>\n",
       "      <th>County FIPS</th>\n",
       "      <th>Census Tract Code</th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>NAME20</th>\n",
       "      <th>NAMELSAD20</th>\n",
       "      <th>MTFCC20</th>\n",
       "      <th>FUNCSTAT20</th>\n",
       "      <th>ALAND20</th>\n",
       "      <th>AWATER20</th>\n",
       "      <th>INTPTLAT20</th>\n",
       "      <th>INTPTLON20</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>025</td>\n",
       "      <td>970101</td>\n",
       "      <td>36025970101</td>\n",
       "      <td>9701.01</td>\n",
       "      <td>Census Tract</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>108853793</td>\n",
       "      <td>691913</td>\n",
       "      <td>+42.4452144</td>\n",
       "      <td>-074.7028619</td>\n",
       "      <td>POLYGON ((-74.79374 42.49635, -74.79359 42.496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>025</td>\n",
       "      <td>970102</td>\n",
       "      <td>36025970102</td>\n",
       "      <td>9701.02</td>\n",
       "      <td>Census Tract</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>133548339</td>\n",
       "      <td>904696</td>\n",
       "      <td>+42.4544478</td>\n",
       "      <td>-074.9018086</td>\n",
       "      <td>POLYGON ((-75.05907 42.43064, -75.05219 42.430...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State FIPS County FIPS Census Tract Code      GEOID20   NAME20  \\\n",
       "0         36         025            970101  36025970101  9701.01   \n",
       "1         36         025            970102  36025970102  9701.02   \n",
       "\n",
       "     NAMELSAD20 MTFCC20 FUNCSTAT20    ALAND20  AWATER20   INTPTLAT20  \\\n",
       "0  Census Tract   G5020          S  108853793    691913  +42.4452144   \n",
       "1  Census Tract   G5020          S  133548339    904696  +42.4544478   \n",
       "\n",
       "     INTPTLON20                                           geometry  \n",
       "0  -074.7028619  POLYGON ((-74.79374 42.49635, -74.79359 42.496...  \n",
       "1  -074.9018086  POLYGON ((-75.05907 42.43064, -75.05219 42.430...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapefiles_dir_tract = os.path.join(shapes_dir,\"tiger2020PL_NY_tracts\") # provide the full path to our shapefiles\n",
    "shapefiles_tract_ny=[x for x in pathlib.Path(shapefiles_dir_tract).iterdir() if x.is_file()] # make a list of all the files in the directory with their full path\n",
    "# shapefiles_tract_ny\n",
    "\n",
    "df_shapes_tract_ny = pd.DataFrame()\n",
    "for file in shapefiles_tract_ny:\n",
    "    df_shapes_tract_ny = pd.concat([df_shapes_tract_ny, gpd.read_file(file)], ignore_index=True, copy=False)\n",
    "    # df_shapes_tract_ny.rename(columns={'STATEFP20': 'State FIPS', 'COUNTYFP20': 'County FIPS', 'TRACTCE20': 'Census Tract Code'}, inplace=True)\n",
    "\n",
    "df_shapes_tract_ny.rename(columns={'STATEFP20': 'State FIPS', 'COUNTYFP20': 'County FIPS', 'TRACTCE20': 'Census Tract Code'}, inplace=True)\n",
    "df_shapes_tract_ny.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145d39e8-990c-44a4-971f-52016b12d8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'STATEFP20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_shapes_tract_ny \u001b[38;5;241m=\u001b[39m \u001b[43mdf_shapes_tract_ny\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_census\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTATEFP20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOUNTYFP20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRACTCE20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mState FIPS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCounty FIPS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTract ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df_shapes_tract_ny = df_shapes_tract_ny[[\"Census Tract Name\", \"Population\", \"geometry\"]]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df_shapes_tract_ny\n",
      "File \u001b[0;32m~/git/portfolio/venv/lib/python3.8/site-packages/geopandas/geodataframe.py:1378\u001b[0m, in \u001b[0;36mGeoDataFrame.merge\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Merge two ``GeoDataFrame`` objects with a database-style join.\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \n\u001b[1;32m   1360\u001b[0m \u001b[38;5;124;03m    Returns a ``GeoDataFrame`` if a geometry column is present; otherwise,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     geo_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geometry_column_name\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, DataFrame) \u001b[38;5;129;01mand\u001b[39;00m geo_col \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "File \u001b[0;32m~/git/portfolio/venv/lib/python3.8/site-packages/pandas/core/frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9320\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9321\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9335\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9348\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9349\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/portfolio/venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/git/portfolio/venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/git/portfolio/venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1110\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(rk)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1111\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/git/portfolio/venv/lib/python3.8/site-packages/pandas/core/generic.py:1848\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1848\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'STATEFP20'"
     ]
    }
   ],
   "source": [
    "df_shapes_tract_ny = df_shapes_tract_ny.merge(df_census, left_on=[\"STATEFP20\", \"COUNTYFP20\", \"TRACTCE20\"], right_on=[\"State FIPS\", \"County FIPS\", \"Tract ID\"], how='inner')\n",
    "# df_shapes_tract_ny = df_shapes_tract_ny[[\"Census Tract Name\", \"Population\", \"geometry\"]]\n",
    "df_shapes_tract_ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ee180-a37d-433e-8211-a179effed760",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_df.loc[ shape_df[\"NAMELSAD\"].str.startswith(\"New York\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33739d6f-f90b-407d-9e7b-1df8ec77bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_shape = shape_df.loc[ shape_df[\"NAMELSAD\"] == \"New York city\" ]\n",
    "ny_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d55923-0f53-4041-a502-e523f40a38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "ny_map = KeplerGl( height=600, show_docs=False)\n",
    "ny_map.add_data(ny_shape, name='New York City')\n",
    "ny_map.add_data(ny_tract_shapes_df, name='Population') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72568770-f2cb-4373-9008-d291865d4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_map.config = {'version': 'v1',\n",
    " 'config': {'visState': {'filters': [],\n",
    "   'layers': [{'id': '657ayan',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'New York City',\n",
    "      'label': 'New York City',\n",
    "      'color': [77, 193, 156],\n",
    "      'highlightColor': [252, 242, 26, 255],\n",
    "      'columns': {'geojson': 'geometry'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'strokeOpacity': 0.8,\n",
    "       'thickness': 1,\n",
    "       'strokeColor': [212, 204, 243],\n",
    "       'colorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'enableElevationZoomFactor': True,\n",
    "       'stroked': True,\n",
    "       'filled': False,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'hidden': False,\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': None,\n",
    "      'colorScale': 'quantile',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}},\n",
    "    {'id': 'g18qutg',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'Population',\n",
    "      'label': 'Population',\n",
    "      'color': [23, 184, 190],\n",
    "      'highlightColor': [252, 242, 26, 255],\n",
    "      'columns': {'geojson': 'geometry'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'strokeOpacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': [246, 209, 138],\n",
    "       'colorRange': {'name': 'Global Warming 8',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#4C0035',\n",
    "         '#650031',\n",
    "         '#7F0023',\n",
    "         '#98000A',\n",
    "         '#B21800',\n",
    "         '#CB4600',\n",
    "         '#E57F00',\n",
    "         '#FFC300']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'enableElevationZoomFactor': True,\n",
    "       'stroked': False,\n",
    "       'filled': True,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'hidden': False,\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': {'name': 'Population',\n",
    "       'type': 'integer'},\n",
    "      'colorScale': 'quantile',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}}],\n",
    "   'interactionConfig': {'tooltip': {'fieldsToShow': {'New York City': [{'name': 'STATEFP',\n",
    "        'format': None},\n",
    "       {'name': 'PLACEFP', 'format': None},\n",
    "       {'name': 'PLACENS', 'format': None},\n",
    "       {'name': 'AFFGEOID', 'format': None},\n",
    "       {'name': 'GEOID', 'format': None}],\n",
    "      'Population': [{'name': 'Census Tract Name', 'format': None},\n",
    "       {'name': 'Population', 'format': None}]},\n",
    "     'compareMode': False,\n",
    "     'compareType': 'absolute',\n",
    "     'enabled': True},\n",
    "    'brush': {'size': 0.5, 'enabled': False},\n",
    "    'geocoder': {'enabled': False},\n",
    "    'coordinate': {'enabled': False}},\n",
    "   'layerBlending': 'normal',\n",
    "   'splitMaps': [],\n",
    "   'animationConfig': {'currentTime': None, 'speed': 1}},\n",
    "  'mapState': {'bearing': 0,\n",
    "   'dragRotate': False,\n",
    "   'latitude': 42.7462215,\n",
    "   'longitude': -75.7700405,\n",
    "   'pitch': 0,\n",
    "   'zoom': 6,\n",
    "   'isSplit': False},\n",
    "  'mapStyle': {'styleType': 'dark',\n",
    "   'topLayerGroups': {},\n",
    "   'visibleLayerGroups': {'label': True,\n",
    "    'road': True,\n",
    "    'border': False,\n",
    "    'building': True,\n",
    "    'water': True,\n",
    "    'land': True,\n",
    "    '3d building': False},\n",
    "   'threeDBuildingColor': [9.665468314072013,\n",
    "    17.18305478057247,\n",
    "    31.1442867897876],\n",
    "   'mapStyles': {}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5b19e-0527-4248-a153-75ad6abb4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd5ed1-54ce-421d-9cb0-f6388d7ec766",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_map.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf26075-6739-4147-afba-f9aa35987c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block loops through our 'ny_shapefiles' list, and creates a separate list of FIPS codes for county and state \n",
    "county_codes=[] # create an empty list for County FIPS\n",
    "state_codes=[] # create an empty list for State FIPS\n",
    "filtered_shapefiles=[]\n",
    "\n",
    "for file in ny_shapefiles: \n",
    "    filename_parts = file.name.replace(\".zip\",\"\").split(\"_\") # take each filename - remove '.zip', split the remaining string wherever \"_\"  appears, and save it as a list\n",
    "    if len(filename_parts) >=3: # take every 'filename_parts' list containing 3 or more elements (fewer than 3 parts indicates a file is extraneous and we don't want it)\n",
    "        if len(filename_parts[2]) ==5: # take from each list the element at index 2 (position 3), but only if it contains 5 digits [State FIPS + County FIPS = 5 digits]\n",
    "            # filename_parts -->  tl_2020_36013_tract20.zip\n",
    "            # 36013 <---filename_parts[2]\n",
    "            # 013 <---filename_parts[2][1:4]\n",
    "            county_codes.append(filename_parts[2][-3:]) # take the last 3 digits of the element at index 2, and append it to the list \n",
    "            state_codes.append(filename_parts[2][0:2])  # take the first 3 digits of the element at index 2, State FIPS, and append it to our list\n",
    "            filtered_shapefiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb1562-131c-482a-b8aa-fa245cba9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets zip our 3 lists into one and call it 'files_to_load'\n",
    "files_list = list(zip(state_codes, county_codes, filtered_shapefiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265f324-8a81-4e67-8153-4f6dbb24095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's turn it into a DataFrame and rename the columns for consistency\n",
    "df_ny_files = pd.DataFrame.from_records(files_list).rename({0: 'State FIPS', 1: 'County FIPS', 2: 'File name'}, axis=1)\n",
    "df_ny_files['State FIPS']=df_ny_files['State FIPS'].astype(int)\n",
    "df_ny_files['County FIPS']=df_ny_files['County FIPS'].astype(int)\n",
    "df_ny_files\n",
    "\n",
    "# let's check out the datatypes\n",
    "df_ny_files.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb81ba-ca85-4928-a045-4304b5c7bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb02b9-219b-4286-a963-c162421e66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes = pd.read_csv('codes.csv')\n",
    "# need to drop column \"unnamed: 0\"\n",
    "df_codes['State FIPS']=df_codes['State FIPS'].astype(int)\n",
    "df_codes['County FIPS']=df_codes['County FIPS'].astype(int)\n",
    "df_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0822f2a-4260-4a62-b448-55bb5e853ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df here with just the files for ny state, including columns: State Name, State FIPS, County, County Fips, File name\n",
    "df_ny_codes_files = pd.merge(df_codes, df_ny_files)\n",
    "df_ny_codes_files\n",
    "df_ny_codes_files.head()\n",
    "# df_ny_codes_files[['State Name', 'State FIPS', 'County', 'County FIPS', 'File name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0b790-db12-4a4b-aa89-70061385f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_codes_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011863da-4b53-413a-bc4f-121040f5cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now I want to load the map of NY state census tracts\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "ny_map = KeplerGl(height=600, show_docs=False)\n",
    "for row in df_ny_codes_files.itertuples():\n",
    "    zipfile = f\"zip://{row[7]}\"\n",
    "    ny_map.add_data(data=gpd.read_file(zipfile), name=row[5])\n",
    "ny_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f39e6-759d-4180-a8b3-38f943cea21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I want to load the population data for just NYC and add it to the map\n",
    "# should i join this with geo_df_nyc?\n",
    "import tarfile\n",
    "\n",
    "# 32mb+ of census data saved in a 4.7mb archive\n",
    "census_data_archive = os.path.join(data_archive_dir, \"census_data_2022_03_01.tgz\")\n",
    "\n",
    "# This is the US Census file with population data we will extract\n",
    "# this file is contained in the above tgz file\n",
    "census_2020_file = \"DECENNIALPL2020.P1_data_with_overlays_2021-12-02T121459.csv\"\n",
    "\n",
    "use_cols = [0, 1, 2]\n",
    "col_names = ['GEOID', 'CENSUS TRACT NAME', 'POPULATION']\n",
    "\n",
    "# This extracts a DataFrame from a tgz archived file\n",
    "def extract_from_tgz(filename):\n",
    "    with tarfile.open(filename) as tf:\n",
    "        for file in tf.getmembers():\n",
    "            if file.name == census_2020_file:\n",
    "                data = tf.extractfile(file)\n",
    "                return pd.read_csv(data, low_memory=False, skiprows=1, header=0, usecols=use_cols, names=col_names)\n",
    "\n",
    "df_census_raw = extract_from_tgz(census_data_archive)\n",
    "\n",
    "# change some options that determine how much data is displayed in the notebook\n",
    "\n",
    "\n",
    "df_census_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a11c52-a102-4953-9d4d-0320f1a6446b",
   "metadata": {},
   "source": [
    "The last 6 digits of the GEOID are the census tract code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758e47f-6639-4891-b714-5894c1d47114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a GEO DataFrame for all of NY State, so that I can add in population data and calculate pop density\n",
    "# geo_df_ny.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75133e4d-fc96-48d6-bcd9-24363cf98145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for later if i want to save the config file for my map\n",
    "#ny_map.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490656e-3442-4591-b1da-5be7968d8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_fp = df_census_raw['GEOID'].str.slice(9,11).rename('State FIPS').astype(int)\n",
    "# county_fp = df_census_raw['GEOID'].str.slice(11,14).rename('County FIPS').astype(int)\n",
    "# df_census_pop = pd.concat([df_census_raw, state_fp, county_fp], axis=1).drop('GEOID', axis=1)\n",
    "# df_census_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e89e10-6ca8-466d-96b0-590e1e385403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a6aa7-ad7a-4800-a224-a286938640b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
