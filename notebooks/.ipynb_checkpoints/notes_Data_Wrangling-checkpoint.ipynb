{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78449c32-0f33-410c-88d3-065a9a4643ce",
   "metadata": {},
   "source": [
    "\n",
    "Data Wrangling & Tidying\n",
    "==========================================\n",
    "\n",
    "The data we receive often needs to be cleaned, transformed, restructured in order to provide any insights. This process is often called \"data wrangling\" or \"data munging.\" A tidy dataset follows three fundamental rules:\n",
    "\n",
    "* Each variable forms a column following the same units measurement \n",
    "* Each observation forms a row\n",
    "* Each type of **observational unit** forms a table\n",
    "\n",
    "An **observational unit** is the individual object or instance that we capture information about. For example, in a study about trees, the observational unit would be each tre\n",
    "\n",
    "A dataset is considered to be in wide-form when at least one variable is represented across multiple columns as column headers rather than in a single column. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb686e6-c0d1-4b32-9916-e3f52920da91",
   "metadata": {},
   "source": [
    "Melt method\n",
    "-------------------\n",
    "\n",
    "Pandas' **.melt() method** helps convert a dataset from wide to long-form. \n",
    "\n",
    "Syntax:\n",
    "\n",
    "    ::\n",
    "\n",
    "       pd.melt(dataset, id_vars = , var_name = , value_name = )\n",
    "\n",
    "The parameters for this function are:\n",
    "\n",
    "* id_vars: name of column(s) of identifier variable(s). If there is more than one identifier variable, it can be written as id_vars\n",
    "* var_name: name for the new single column containing the column names that are being combined \n",
    "* value_name: name for the bew single column of values.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36511db0-bf0d-4e5e-8d95-22070bfe3724",
   "metadata": {},
   "source": [
    "data = pd.read_csv(\"players.csv\")\n",
    "data_tidy = pd.melt(data, id_vars=[\"Day\", \"Player\"], var_name=\"Game\", value_name=\"Score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb219e-0b89-4f3d-b800-bbb8abcc87c5",
   "metadata": {},
   "source": [
    "Pivot method\n",
    "------------------\n",
    "\n",
    "A dataset is considered “too long” when a single column in the dataset represents more than one variable, thus creating unecessary extra rows. Another way to think about it is that all numbers in a single column should have the same unit. Pandas' pivot method is useful here.\n",
    "\n",
    "The pivot method allows us to reshape a dataset based on the values of a column. \n",
    "\n",
    "Syntax:\n",
    "\n",
    "    ::\n",
    "\n",
    "          pd.pivot(index = , columns = , values = ).reset_index\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "* index: name of the column to make the new data frame's index \n",
    "* columns: name of the column to make the new DF's column headers \n",
    "* values: name of the column that will populate the new data frame's values \n",
    "\n",
    "Using the function .reset_index() and specifying .columns.name = None clears up some of the indexing that was carried over from the original form of the data set. \n",
    "\n",
    "Example:\n",
    "\n",
    "    ::\n",
    "\n",
    "        data = pd.read_csv(\"countries.csv\")\n",
    "        data_tidy = data.pivot(index = 'Country', columns = 'Feature', values = 'Observation').reset_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbe293-c12e-4fa6-94ac-a49c8400ae21",
   "metadata": {},
   "source": [
    "Using Pandas to Clean Data\n",
    "==========================================\n",
    "\n",
    "https://www.codecademy.com/paths/data-analyst/tracks/dacp-data-wrangling-and-tidying/modules/dscp-fundamentals-of-data-wrangling-and-tidying/articles/intro-data-wrangling-and-tidying\n",
    "\n",
    "The power of pandas is mainly in being able to manipulate large amounts of structured data. The first step of diagnosing whether or not a dataset is tidy is using pandas functions to explore and probe the dataset. Some of the most useful functions are:\n",
    "\n",
    "To get an overall sense of the data:\n",
    "\n",
    "* .head() — displays the first 5 rows of the table\n",
    "* .info() — displays a summary of the table\n",
    "* .describe() — displays summary statistics for the table\n",
    "* .columns — displays column names of the table\n",
    "* .value_counts() — displays the distinct values for a column\n",
    "* .shape() - identifies the number of rows and columns in our dataset as (rows, columns)\n",
    "* .dtypes - appends data types to our dataframe. Types of variables: float64, object, int64, bool, and datetime64. \n",
    "  \n",
    "  ::\n",
    "      \n",
    "    print(restaurants.dtypes)\n",
    "\n",
    "* .nunique() - looks at the number of unique values in each column\n",
    "\n",
    "\n",
    "Cleaning up:\n",
    "\n",
    "* .rename() - relabels columns, taking a dictionary, axis=1 refers to the columns, axis=0 would refer to the rows\n",
    "  \n",
    "  ::\n",
    "      \n",
    "      restaurants = restaurants.rename({'dba': 'name', 'cuisine description': 'cuisine'}, axis=1)\n",
    "\n",
    "* .drop_duplicates() - removes duplicate rows\n",
    "* tr.lstrip() to remove the prefixes\n",
    "* isna() returns a boolean, which indicates if the observation in that column is missing (True) or not (False)\n",
    "* map() function can be use with lower() and str() : restaurants.columns = map(str.lower, restaurants.columns) to create consistency\n",
    "* crosstab() computes the frequency of two or more variables. We can use it with isna() tto identify if there is an NaN in that column. \n",
    "* melt() function \n",
    "* string.lower\n",
    "\n",
    "    ::\n",
    "        \n",
    "        df['shoe_type'] = df.shoe_type.apply(string.lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1fc97-ea74-44df-aeb6-d21050a182e8",
   "metadata": {},
   "source": [
    "Dealing with Multiple Files\n",
    "-------------------------------\n",
    "\n",
    "We can combine the use of **glob**, a Python library for working with files, with pandas to better organize data that is separated into multiple files. Glob can open multiple files by using regex matching to get the filenames.\n",
    "\n",
    "The below code goes through any file that starts with 'file' and has an extension of .csv. It opens each file, reads the data into a DataFrame, and then concatenates all of those DataFrames together.\n",
    "\n",
    "    ::\n",
    "\n",
    "        import glob\n",
    "        \n",
    "        files = glob.glob(\"file*.csv\")\n",
    "        \n",
    "        df_list = []\n",
    "        for filename in files:\n",
    "        data = pd.read_csv(filename)\n",
    "        df_list.append(data)\n",
    "        \n",
    "        df = pd.concat(df_list)\n",
    "        \n",
    "        print(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6762-2aa4-458d-8aed-a6ca65f33cab",
   "metadata": {},
   "source": [
    "Regular Exressions\n",
    "---------------------------\n",
    "\n",
    "**Regular expressions** are special sequences of characters that describe a pattern of text that needs to be found. Regular expressions operate by moving through a piece of text, character by character, from left to right. When a character is found that matches the first piece of the expression, it looks to find a continuous sequence of matching characters.\n",
    "\n",
    "* **Literals** are regular expression that contain the exact text we want to match. \n",
    "* **Alternation** allows us to match the text preceding or following the pipe symbol \\|\\.\n",
    "\n",
    "    ::\n",
    "        \n",
    "        apples|pears\n",
    "\n",
    "* **Character sets** are denoted by brackets [ ] and let us match one character from a series of characters. The letters inside are the different possibilities for the character that appears in that position. We can also place the caret symbol **^** in front to negate our characters sets, matching any character *not* listed in brackets. \n",
    "\n",
    "    ::\n",
    "        \n",
    "        [cat] \n",
    "        # will match characters c, a, or t, but not the text cat \n",
    "        \n",
    "        [^cat] \n",
    "        # will match any character that is *not* c, a, or t\n",
    "\n",
    "  \n",
    "* **Grouping** or **capture groups** lets us group parts of a regular expresssion together and limit the reach of the |to the text within ():\n",
    "  \n",
    "    ::\n",
    "\n",
    "        I love (baboons|gorillas)\n",
    "        # will match \"I love\" and then either \"baboons\" or \"gorillas\"\n",
    "\n",
    "\n",
    "\n",
    "* **Wildcards** are represented by a period or dot . and will match any single character (letter, number, symbol or whitespace). We can use the escape character \\when we want to match an actual period. \n",
    "\n",
    "    ::\n",
    "\n",
    "        .........\n",
    "        # will completely match any 9-character piece of text! \n",
    "\n",
    "        Howler monkeys are really lazy\\.\n",
    "        # will completely match the text \"Howler monkeys are really lazy.\"\"\n",
    "\n",
    "* **Ranges** allow us to specify a range of characters in which we can make a match, without having to type out each one. The - indicates that we are matching a range. \n",
    "\n",
    "    ::\n",
    "        \n",
    "       [a-d]\n",
    "       # would match any character a, b, or c\n",
    "       # the above is equivalent to [a, b, c, d]\n",
    "\n",
    "\n",
    "A range can be used to match any single:\n",
    "\n",
    "* capital letter [A-Z]\n",
    "* lowercase letter [a-z]\n",
    "* digit [0-9]\n",
    "\n",
    "We can also match multiple ranges in the same set.\n",
    "\n",
    "    ::\n",
    "        \n",
    "        [A-Za-z]\n",
    "        # would let us match any single capital or lowercase alphabetical character\n",
    "\n",
    "* **Shorthand character classes** make writing regular expressions much simpler by representing common ranges. Examples include: \\w word characters, \\d digit characters, \\s whitespace characters  \n",
    "* **Groupings**, denoted with parentheses (), group parts of a regular expression together, and allows us to limit alternation to part of a regex\n",
    "* **Fixed quantifiers**, represented with curly braces {}, let us indicate the exact quantity or a range of quantity of a character we wish to match. Note - quantifiers are greedy - they will match the **greatest quantity** of characters they possibly can and ignore smaller matches.\n",
    "* **Optional quantifiers**, indicated by the question mark ?, allow us to indicate a character in a regex is optional, meaining it can appear either 0 or 1 time. They only apply to the character directly before the *?* (Note - since ? is a metacharacter, we need to use the escape character \\ in our regex in order to match a question mark ? in a piece of text.)\n",
    "* **The Kleene star** is also a quantifier and matches the preceding character 0 or more times, meaning the character doesn't need to appear, can appear once, or can appear many times. It is denoted with the asterisk *.\n",
    "  \n",
    "    ::\n",
    "\n",
    "        meo*w \n",
    "        # will match \"me\", followed by 0 or more \"o\", followed by \"w\". \n",
    "        # Thus the regex will match \"mew\", \"meow\", \"meooow\", and \"meoooooooooooow\".\n",
    "* **The Kleene plus**, denoted by the plus +, matches the preceding character 1 or more times.\n",
    "\n",
    "    ::\n",
    "\n",
    "        meo+w \n",
    "        # will match the characters \"me\", followed by 1 or more \"o\", followed by a \"w\". \n",
    "        # Thus the regex will match \"meow\", \"meooow\", and \"meoooooooooooow\", but not match mew.\n",
    "\n",
    "* **The anchor symbols** hat ^ and dollar sign $ are used to match text at the start and end of a string, respectively\n",
    "\n",
    "    ::\n",
    "\n",
    "        \\w{3} \n",
    "        # will match exactly 3 word characters\n",
    "\n",
    "        \\w{4,7} \n",
    "        # will match at minimum 4 and at maximum 7 word characters\n",
    "\n",
    "        roa{3}r \n",
    "        # will match the characters \"ro\" followed by 3 \"a\", and then the character \"r\"\n",
    "\n",
    "        mo{2,4} \n",
    "        # quantifiers are greedy - they will match the text \"moooo\" in the string \"moooo\", but not return a match of \"moo\" or \"mooo\"\n",
    "\n",
    "    ::\n",
    "        \n",
    "        humou?r \n",
    "        # matches the characters \"humo\" then either 0 or 1 occurrence of \"u\" and finally \"r\" .\n",
    "\n",
    "* **Anchors** ensure that we do not match unintended text by making the expression as specific as possible. The anchors hat ^ and dollar sign $ are used to match text at the start and the end of a string, respectively. \n",
    "\n",
    "    ::\n",
    "\n",
    "        ^Monkeys: my mortal enemy$ \n",
    "        # ^ ensures that the matched text begins with \"Monkeys\", the $ ensures the matched text ends with \"enemy\".\n",
    "        # will completely match \"Monkeys: my mortal enemy\" \n",
    "        # will not match \"Spider Monkeys: my mortal enemy in the wild\" or \"Squirrel Monkeys: my mortal enemy in the wild\" \n",
    "        # Without the anchor tags, the regex Monkeys: my mortal enemy will match the text Monkeys: my mortal enemy in both Spider Monkeys: my mortal enemy in the wild and Squirrel Monkeys: my mortal enemy in the wild.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844be59e-6aea-41e5-8f3b-26e169c18088",
   "metadata": {},
   "source": [
    "Splitting\n",
    "---------------------------------\n",
    "\n",
    "Sometimes we receive data with columns that contain more than one type of data. We can use splitting to correct this. \n",
    "\n",
    "We can splitting by index when at least one of the parts is a set number of characters.\n",
    "\n",
    "We can also split by character - good when the part to be split may vary in length but is always separated by a specific character.\n",
    "\n",
    "This might be used to extract numbers contained within a string using pandas' **.str.split()** function with **regex**\n",
    "\n",
    "  :: \n",
    "  \n",
    "    students['grade'].str.split('(\\d+)', expand=True[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9313d01-1b07-4428-900e-f95519baa1a6",
   "metadata": {},
   "source": [
    "Data Types\n",
    "----------------------------------\n",
    "Each column of a DataFrame can hold items of the same data type or dtype. Series objects compose all DataFrames.The dtypes that pandas uses are: float, int, bool, datetime, timedelta, category and object. Sometimes we'll want to convert types to make the data easier to work with. To see the types of each column of a DataFrame, we can use:\n",
    "\n",
    "    ::\n",
    "\n",
    "    print(df.dtypes)\n",
    "\n",
    "The pandas' function .to_numeric() lets us convert strings containing numerical values to integers or floats. \n",
    "\n",
    "    ::\n",
    "\n",
    "    fruit.price = pd.to_numeric(fruit.price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdbbb6-0ff3-4cff-81b3-f96f72c4f88e",
   "metadata": {},
   "source": [
    "String Parsing \n",
    "----------------------------------\n",
    "\n",
    "\n",
    "Remove or replace unwanted characters using **.replace()** and **regex**\n",
    "\n",
    "  :: \n",
    "    \n",
    "    students.score = students['score'].replace('[\\%,]', '', regex=True)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "Duplicate rows can be removed using **.drop_duplicates()**. To remove only rows where the duplicate appears in certain columns, we can select subsets containing specifying which columns to look at.\n",
    "\n",
    "  :: \n",
    "    \n",
    "    df = df.drop_duplicates() ????\n",
    "    df = df.drop_duplicates(subset=['reps'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5f3d1-d0f5-4848-a964-d7c43dd438f5",
   "metadata": {},
   "source": [
    "Missing Values\n",
    "=================\n",
    "\n",
    "\n",
    "Pandas provides the **isna()** and **notna()** functions to make detecting missing values easier. Some calculations will just skip NaN values, but others will break when NaN is encountered.\n",
    "\n",
    "Using **.dropna()** will result in the DataFrame without the incomplete rows. We can also select a specific subset if we want to remove only rows containing NaN in specific columns.\n",
    "\n",
    "We can use **.fillna()** to fill in missing values with the mean of the column or with some other aggregate value.\n",
    "\n",
    "  :: \n",
    "  \n",
    "    df['column_name'] = df['column_name'].fillna(value_to_fill_in)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bbd6c2-9d0d-405e-bee4-f0400c4b2220",
   "metadata": {},
   "source": [
    "Some helpful Python string methods\n",
    "=====================================\n",
    "\n",
    "Python string method .replace( ). ?? Check if needs to be saved as new variables to \"stick\" ??\n",
    "\n",
    "    ::\n",
    "        \n",
    "        updated_medical_data = medical_data.replace(\"#\", \"$\")\n",
    "    \n",
    "Python split() functions.\n",
    "\n",
    "    ::\n",
    "        \n",
    "        medical_data_split = updated_medical_data.split(\";\")\n",
    "    \n",
    "\n",
    "Python .strip() method removes spaces at the beginning and at the end of the string. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73540a3-6a48-44b8-ab51-bc4c801e9406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
