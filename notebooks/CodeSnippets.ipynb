{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67301e36-e470-49cd-a968-0dcb7bb7a562",
   "metadata": {},
   "source": [
    "Snippet from notebooks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617936b7-9f61-43d9-bd29-def307e795d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_fp = df_census_pop_raw['GEOID'].str.slice(9,11).rename('State FIPS').astype(int)\n",
    "# county_fp = df_census_pop_raw['GEOID'].str.slice(11,14).rename('County FIPS').astype(int)\n",
    "# df_census_pop = pd.concat([df_census_pop_raw, state_fp, county_fp], axis=1).drop('GEOID', axis=1)\n",
    "# df_census_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a13368-b7d1-490b-a432-279d9cc448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the re module provides regex matching operations\n",
    "# import re \n",
    "\n",
    "# shapefile_tract = os.path.join(shapes_dir,\"tiger2020PL_NY_tracts\") # provide the full path to our shapefiles\n",
    "# shapefile_tract_ny=[x for x in pathlib.Path(shapefile_tract).iterdir() if x.is_file()] # make a list of all the files in the directory with their full path\n",
    "\n",
    "# tract_file_re = \"tl_2020_[0-9]{5}\" # use regex to find filenames containing a digit in the range 0-9, repeated 5 times \n",
    "# shapefile_tract_ny=[x for x in pathlib.Path(shapefile_tract).iterdir() if x.is_file() and re.search(tract_file_re, x.name)] # make a list of all files in the dir with their full path, as long as they meet above criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fe0ca-af10-4bdd-a6e8-39b5125ceb0b",
   "metadata": {},
   "source": [
    "Given the [hierarchy through which census geographic entities are organized](https://www2.census.gov/geo/pdfs/reference/geodiagram.pdf), accessing New York City geographic data at the census tract level is not as straightforward as one might expect. Rather, we'll begin with the full set of NY state files, map population density, then draw a boundary around New York City. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306506de-7ec4-408e-ac00-29d2925c3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myshapefile = os.path.join(shapes_dir, '/home/julie/git/portfolio/data/shapes/tiger2020PL_NY_tracts/tl_2020_36003_tract20.zip')\n",
    "# mygeodf = gpd.read_file(myshapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903bf45e-9b88-4c1b-a43a-9ed1c8494e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_state = pd.read_csv(file_state, \n",
    "#                        usecols=['STATE', 'STUSAB', 'STATE_NAME'], # use only these columns\n",
    "#                        delimiter=\"|\", # load txt file as pandas DataFrame \n",
    "#                        encoding=\"iso-8859-1\", \n",
    "#                        encoding_errors='ignore')[['STATE_NAME', 'STUSAB', 'STATE',]] # reorder cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e81823a-bf41-48b4-af25-16fb5d093741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # search for any rows containing a comma in the \"County\" column\n",
    "# df_place[df_place['County'].str.contains(',')]\n",
    "\n",
    "# # srs_place_expanded = (df_place['County']\n",
    "# #                           .str.strip( ) # strip any leading/trailing spaces\n",
    "# #                           .str.split(\",\", expand=True) # split the string wherever a comma appears\n",
    "# #                           .melt(ignore_index=False) # we want to preserve the index here, so we can use join to add it back to df_place\n",
    "# #                           .dropna() # drop any rows with null values\n",
    "# #                           .drop('variable', axis=1) # drop the new index column (labeled 'variable')\n",
    "# #                           .rename(columns={'value': 'County'})\n",
    "# #                          )\n",
    "\n",
    "# # strip any leading/trailing spaces\n",
    "# # split the string wherever a comma appears\n",
    "# srs_place_expanded = (df_place['County'].str.strip( ).str.split(\",\", expand=True)) \n",
    "\n",
    "# # we want to preserve the index here, so we can use join to add it back to df_place\n",
    "# # .dropna() # drop any rows with null values\n",
    "# # .drop('variable', axis=1) # drop the new index column (labeled 'variable')\n",
    "# # .rename(columns={'value': 'County'})\n",
    "# srs_place_expanded = srs_place_expanded.melt(ignore_index=False).dropna().drop('variable', axis=1).rename(columns={'value': 'County'})\n",
    "                          \n",
    "# # rejoin our series into our df\n",
    "# # adding rsuffix '_messy' as a reminder that this is the 'County' column we'll be dropping shortly\n",
    "# df_place_expanded = srs_place_expanded.join(df_place, rsuffix='_messy')\n",
    "\n",
    "# # now let's drop \"County_messy\"\n",
    "# df_place_expanded = df_place_expanded.drop(['County_messy'], axis=1)\n",
    "\n",
    "# # reorder the columns\n",
    "# df_place_expanded = df_place_expanded[['State', 'State FIPS', 'Place', 'Place FIPS', 'County']]\n",
    "# df_place_expanded\n",
    "\n",
    "# # let's look at New York City to make sure the melt worked and each county really is in a new row \n",
    "# df_place_expanded.loc[df_place_expanded['Place'] == (\"New York city\")]\n",
    "# # df_place_expanded.loc[df_place_expanded['Place'].str.startswith(\"New York\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1ddfde-5a88-4548-98cc-67938c629173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_codes = pd.merge(df_place_expanded, df_county, on=['State', 'State FIPS', 'County'], how = 'left') \n",
    "# df_codes =  df_codes[['State Name', 'State', 'State FIPS', 'Place', 'Place FIPS', 'County', 'County FIPS']] \n",
    "# df_codes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37ec499-5a3f-4359-a402-5bf53a94cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need to strip whitepsace from df_place['County'] (apparently the melt thing above didn't do it...!)\n",
    "# df_place_expanded['County'] = df_place_expanded['County'].str.strip()\n",
    "# df_place_expanded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18878d16-3e8d-4372-b648-51ca37db360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_state['State FIPS'] = df_state['State FIPS'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb58ff2-aec9-435c-9d40-8f38b31b744b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m geodf_tract_ny \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame() \u001b[38;5;66;03m# create any empty DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m shapefile_tract_ny: \u001b[38;5;66;03m# for every file in our list of shapefiles\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     gpd\u001b[38;5;241m.\u001b[39mread_file(file) \u001b[38;5;66;03m# read the file into a GEO DataFrame\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "geodf_tract_ny = pd.DataFrame() # create any empty DataFrame\n",
    "for file in shapefile_tract_ny: # for every file in our list of shapefiles\n",
    "    gpd.read_file(file) # read the file into a GEO DataFrame\n",
    "    geodf_tract_ny = pd.concat([geodf_tract_ny, gpd.read_file(file)], ignore_index=True, copy=False) # concatenate each GEO DataFrame to geodf_tract_ny\n",
    "\n",
    "geodf_tract_ny = geodf_tract_ny[['STATEFP20', 'COUNTYFP20', 'TRACTCE20', 'GEOID20', 'ALAND20', 'geometry']]\n",
    "geodf_tract_ny = geodf_tract_ny.rename(columns={'STATEFP20': 'State FIPS', 'COUNTYFP20': 'County FIPS', 'TRACTCE20': 'Census Tract Code', 'GEOID20': 'GEOID Census Tract', 'ALAND20': 'Land Area'}, inplace=True)\n",
    "geodf_tract_ny = geodf_tract_ny.astype({'STATEFP20': 'int', 'COUNTYFP20':'int', 'TRACTCE20':'int', 'GEOID20': 'int', 'ALAND20': 'int'}).dtypes\n",
    "geodf_tract_ny   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7569b80-14c9-4f4d-8860-8d5d057c735a",
   "metadata": {},
   "source": [
    "# Create a DataFrame with a list of files from a folder\n",
    "**...and split out the STATE FIPS and COUNTY FIPS codes from the filename.** We did this so that we have a df that has filenames of shapefiles along with the state FIPS and county FIPS they pertain to. We could use this to pre-filter the list of files we want to load using GeoPandas to only the shape files for a particular set of counties. For example, if we only want Bronx County - STATE FIPS 36 and COUNTY FIPS 57 - we could find the DF with these two numbers and only load the one file in that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c30539-6bb7-42d3-99c8-ede26980f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block loops through our 'ny_shapefiles' list, and creates a separate list of FIPS codes for county and state \n",
    "county_codes=[] # create an empty list for County FIPS\n",
    "state_codes=[] # create an empty list for State FIPS\n",
    "filtered_shapefiles=[]\n",
    "\n",
    "for file in ny_shapefiles: \n",
    "    filename_parts = file.name.replace(\".zip\",\"\").split(\"_\") # take each filename - remove '.zip', split the remaining string wherever \"_\"  appears, and save it as a list\n",
    "    if len(filename_parts) >=3: # take every 'filename_parts' list containing 3 or more elements (fewer than 3 parts indicates a file is extraneous and we don't want it)\n",
    "        if len(filename_parts[2]) ==5: # take from each list the element at index 2 (position 3), but only if it contains 5 digits [State FIPS + County FIPS = 5 digits]\n",
    "            # filename_parts -->  tl_2020_36013_tract20.zip\n",
    "            # 36013 <---filename_parts[2]\n",
    "            # 013 <---filename_parts[2][1:4]\n",
    "            county_codes.append(filename_parts[2][-3:]) # take the last 3 digits of the element at index 2, and append it to the list \n",
    "            state_codes.append(filename_parts[2][0:2])  # take the first 3 digits of the element at index 2, State FIPS, and append it to our list\n",
    "            filtered_shapefiles.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26aa51-564f-4de0-a1bf-77098067c642",
   "metadata": {},
   "source": [
    "# Using Pyarrow and Parquet on Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7f5d6-dfdc-49cd-acb3-dc31b20a5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_ny_shapefile = \"../data/shapes/tiger2020PL_NY_tracts/tl_2020_36_tract20.zip\"\n",
    "small_clean_shapefile = \"../data_archive/clean/tl_2020_36_tract20.parquet\"\n",
    "\n",
    "import geopandas as gpd\n",
    "ny_shapes_df = gpd.read_file(big_ny_shapefile)[[\"GEOID20\", \"geometry\"]]\n",
    "#ny_shapes_df['STATEFP20'] = ny_shapes_df['STATEFP20'].astype(int)\n",
    "#ny_shapes_df['COUNTYFP20'] = ny_shapes_df['COUNTYFP20'].astype(int)\n",
    "#ny_shapes_df['TRACTCE20'] = ny_shapes_df['TRACTCE20'].astype(int)\n",
    "\n",
    "import pyarrow as pa\n",
    "import warnings; \n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "ny_shapes_df.to_parquet(small_clean_shapefile, index=False, compression='BROTLI')\n",
    "    #= pa.Table.from_pandas(ny_shapes_df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca4a53-3383-4b32-9f78-dfbf9d38c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shapely.geometry.polygon as sp\n",
    "import pandas as pd\n",
    "\n",
    "def shrink_coords(polygon):\n",
    "    if polygon.type != 'Polygon':\n",
    "        return polygon\n",
    "    x, y = polygon.exterior.coords.xy\n",
    "    x = np.around(x, 5)\n",
    "    y = np.around(y, 5)\n",
    "    return sp.Polygon(list(zip(x,y)))\n",
    "\n",
    "# Note: in this next line the simplify() function is  \"supposed\" to make a shape with \n",
    "# many points \"simpler\" (fewer points) / smaller\n",
    "# Hwever,  in practice it either makes no difference or sometimes makes the file larger\n",
    "#ny_shapes_df[\"geometry\"].simplify(tolerance=5)\n",
    "\n",
    "ny_shapes_df[\"geometry\"] = ny_shapes_df[\"geometry\"].apply(shrink_coords)\n",
    "\n",
    "smaller_clean_shapefile = \"../data_archive/clean/tl_2020_36_tract20_simp.parquet\"\n",
    "ny_shapes_df.to_parquet(smaller_clean_shapefile, index=False, compression='BROTLI')\n",
    "ny_shapes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37093f-7708-4647-b605-98f071c331ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ny_shapes_df[\"geometry\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c22a2e-5e89-49b3-981b-177f54695e93",
   "metadata": {},
   "source": [
    "<!-- The Tally page tells us there are 3,143 Counties & Equivalents in the 50 states and DC. (This does not include Puerto Rico and the Island Areas.) We can check if the number of rows in our DF looks right by selecting all states and excluding PR (72), American Samoa (60), Guam (66), Commonwealth of the Northern Mariana Islands (69), United States Virgin Islands (78) and comparing this to the Tally page count (3,143). -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
