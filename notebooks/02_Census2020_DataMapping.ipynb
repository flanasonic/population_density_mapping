{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943e7775-31cf-43cf-95cb-77b18fe7f1d0",
   "metadata": {},
   "source": [
    "# Mapping US Census Tracts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e96a7-37ba-4b6f-94e5-73427bc0d2e2",
   "metadata": {},
   "source": [
    "### Code to help manage our file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f1dee3-8235-4fc9-8bc5-8fb19ae2952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "base_dir = pathlib.Path(os.getcwd()).parent\n",
    "data_archive_dir = os.path.join(base_dir, \"data_archive\")\n",
    "clean_data_dir = os.path.join(data_archive_dir, \"clean\")\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "shapes_dir = os.path.join(data_dir,\"shapes\")\n",
    "json_dir = os.path.join(data_dir,\"geojson\")\n",
    "util_dir = os.path.join(data_dir,\"util\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df985214-e623-4be1-8b75-ff8f710b0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the geopandas function read_file to grab our file\n",
    "import geopandas as gpd\n",
    "\n",
    "# tract_shapefiles_dir = os.path.join(shapes_dir,\"tiger2020PL_NY_tracts\") # provide the full path for the directory containing our shapefiles\n",
    "# ny_shapefiles=[x for x in pathlib.Path(tract_shapefiles_dir).iterdir() if x.is_file()] # make a list of all the files in the directory with their full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388a78e-8829-4380-8a11-8093dea774d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keplergl import KeplerGl\n",
    "# ny_map = KeplerGl(height=600, show_docs=False)\n",
    "# for row in df_ny.itertuples():\n",
    "#     zipfile = f\"zip://{row[7]}\"\n",
    "#     ny_map.add_data(data=gpd.read_file(zipfile), name=row[5])\n",
    "# ny_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff922a96-6e00-4f73-8ab6-b576983ffdf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ny' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeplergl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeplerGl\n\u001b[1;32m      2\u001b[0m ny_map \u001b[38;5;241m=\u001b[39m KeplerGl(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m, show_docs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_ny\u001b[49m\u001b[38;5;241m.\u001b[39mitertuples():\n\u001b[1;32m      4\u001b[0m     zipfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     ny_map\u001b[38;5;241m.\u001b[39madd_data(data\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mread_file(zipfile), name\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ny' is not defined"
     ]
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "ny_map = KeplerGl(height=600, show_docs=False)\n",
    "ny_map.add_data(data=gpd.read_file(zipfile), name=row[5])\n",
    "ny_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d93e6d-2269-4754-a402-96842d12c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this code block loops through our 'ny_shapefiles' list, and creates a separate list of FIPS codes for county and state \n",
    "# county_codes=[] # create an empty list for County FIPS\n",
    "# state_codes=[] # create an empty list for State FIPS\n",
    "# filtered_shapefiles=[]\n",
    "# for file in ny_shapefiles: \n",
    "#     filename_parts = file.name.replace(\".zip\",\"\").split(\"_\") # take each filename - remove '.zip', split the remaining string wherever \"_\"  appears, and save it as a list\n",
    "#     if len(filename_parts) >=3: # take every 'filename_parts' list containing 3 or more elements (fewer than 3 parts indicates a file is extraneous and we don't want it)\n",
    "#         if len(filename_parts[2]) ==5: # take from each list the element at index 2 (position 3), but only if it contains 5 digits [State FIPS + County FIPS = 5 digits]\n",
    "#             # filename_parts -->  tl_2020_36013_tract20.zip\n",
    "#             # 36013 <---filename_parts[2]\n",
    "#             # 013 <---filename_parts[2][1:4]\n",
    "#             county_codes.append(filename_parts[2][-3:]) # take the last 3 digits of the element at index 2, and append it to the list \n",
    "#             state_codes.append(filename_parts[2][0:2])  # take the first 3 digits of the element at index 2, State FIPS, and append it to our list\n",
    "#             filtered_shapefiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3abb6-0e2b-4256-b3d0-a9adbb1a8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(county_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fae9a6-1842-49e1-8eb2-ee14f8b70190",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(state_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110ecd4-8967-4493-8d50-04b1fe60add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets zip our 3 lists into one and call it 'files_to_load'\n",
    "files_to_load = list(zip(state_codes, county_codes, filtered_shapefiles))\n",
    "\n",
    "# now let's turn it into a DataFrame and rename the columns for consistency\n",
    "df_ny_shapes = pd.DataFrame.from_records(files_to_load).rename({0: 'State FIPS', 1: 'County FIPS', 2: 'File name'}, axis=1)\n",
    "# df_ny_shapes = pd.DataFrame.from_records(files_to_load)\n",
    "df_ny_shapes\n",
    "\n",
    "# to ensure the dtypes of the State and County codes are correctly cast as integers, let's set them here\n",
    "df_ny_shapes['State FIPS'] = df_ny_shapes['State FIPS'].astype(int)\n",
    "df_ny_shapes['County FIPS'] = df_ny_shapes['County FIPS'].astype(int)\n",
    "df_ny_shapes.info()\n",
    "df_ny_shapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008f1c0-54f1-42e2-b300-6bd69ed421b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge our two DataFrames into one that contains just the counties within New York City and the full path to their shapefile\n",
    "df_ny = df_nyc_codes.merge(df_ny_shapes)\n",
    "df_ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18750d-443a-43ad-97c8-822c82512cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create a GEO DataFrame with just the columns we need and rename them for consistency\n",
    "import geopandas as gpd\n",
    "\n",
    "zipfile = os.path.join(shapes_dir, 'tiger2020PL_NY_tracts/tl_2020_36005_tract20.zip')\n",
    "geo_df = gpd.read_file(zipfile)[['STATEFP20','COUNTYFP20', 'TRACTCE20',\n",
    "                                 'GEOID20', 'ALAND20', 'geometry']].rename(\n",
    "                                    {'STATEFP20': 'State FIPS','COUNTYFP20': 'County FIPS', \n",
    "                                     'TRACTCE20': 'Census Tract', 'GEOID20': 'GEOID', 'ALAND20': 'Land Area'}, axis=1\n",
    "                                    )\n",
    "\n",
    "geo_df\n",
    "\n",
    "### this is the longer way of writing the above code\n",
    "#geo_df = gpd.read_file(zipfile)\n",
    "\n",
    "# geo_df['State FIPS'] = geo_df['State FIPS'].astype(int)\n",
    "# geo_df['County FIPS'] = geo_df['County FIPS'].astype(int)\n",
    "# geo_df['Census Tract'] = geo_df['Census Tract'].astype(int)\n",
    "# geo_df['GEOID'] = geo_df['GEOID'].astype(int)\n",
    "# geo_df\n",
    "# make a geo dataframe for each of the 5 counties\n",
    "# concatenate into one big DF and map it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946b12e-9ab6-45d4-995b-9388dd778370",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4714bd0-347f-4451-bf0f-8139c9fc07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ny_map.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc9511-352c-4876-b85d-d9cc1828bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# 32mb+ of census data saved in a 4.7mb archive\n",
    "census_data_archive = os.path.join(data_archive_dir, \"census_data_2022_03_01.tgz\")\n",
    "\n",
    "# This is the US Census file with population data we will extract\n",
    "# this file is contained in the above tgz file\n",
    "census_2020_file = \"DECENNIALPL2020.P1_data_with_overlays_2021-12-02T121459.csv\"\n",
    "\n",
    "use_cols = [0, 1, 2]\n",
    "col_names = ['GEOID', 'CENSUS TRACT NAME', 'POPULATION']\n",
    "\n",
    "# This extracts a DataFrame from a tgz archived file\n",
    "def extract_from_tgz(filename):\n",
    "    with tarfile.open(filename) as tf:\n",
    "        for file in tf.getmembers():\n",
    "            if file.name == census_2020_file:\n",
    "                data = tf.extractfile(file)\n",
    "                return pd.read_csv(data, low_memory=False, skiprows=1, header=0, usecols=use_cols, names=col_names)\n",
    "\n",
    "df_census_raw = extract_from_tgz(census_data_archive)\n",
    "\n",
    "# change some options that determine how much data is displayed in the notebook\n",
    "\n",
    "\n",
    "df_census_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a94ea5-7056-4c0c-95f5-0970bc8f0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_fp = df_census_raw['GEOID'].str.slice(9,11).rename('State FIPS').astype(int)\n",
    "# county_fp = df_census_raw['GEOID'].str.slice(11,14).rename('County FIPS').astype(int)\n",
    "# df_census_pop = pd.concat([df_census_raw, state_fp, county_fp], axis=1).drop('GEOID', axis=1)\n",
    "# df_census_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd13eb-5bd5-4a7b-a890-b14c20ef9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_codes.merge(df_census_pop, on=['State FIPS', 'County FIPS'], how='inner')\n",
    "#df_codes.dtypes\n",
    "df_ny = df_ny_shapes.merge(df_all, on=['State FIPS', 'County FIPS'], how='inner')\n",
    "df_ny\n",
    "# This is probably not the dataframe we want\n",
    "# the rows are at a Census Tract Level of Granularity\n",
    "# but I merged in files... which are at a county level of granularity\n",
    "# .. we want to load the files for the counties we want.. ONCE...\n",
    "# so either... filter this list to the rows you want and then find\n",
    "# the \"unique\" list of filenames you want.... \n",
    "# see paragrap below this for an example... the county filenames\n",
    "# are repeated across all the census tracts for NY..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bd730-fd34-4c93-b1ec-b5294eec7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ny.loc[df_ny['Place'] == 'New York City']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcd5-f8df-4005-8630-5baf21ce2965",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "**Choropleth**\n",
    "A choropleth  is a map made of different colored polygons, where each color represents a different quantity or range of quantities. \n",
    "\n",
    "**Shapefile**\n",
    "A standardize file format for storing geospatial information, including geometry (coordinates) and attributes of geographic features, needed to create maps. \n",
    "\n",
    "**TIGER?**\n",
    "TIGER, also referred to as MAF/TIGER, is the Census Bureau's geographic database system. The acronym MAF/TIGER stands for Master Address. File/Topologically Integrated Geographic Encoding and Referencing. \n",
    "\n",
    "**GeoJSON** \n",
    "A format for storing a variety of geographic data and is based on JSON. We know that JSON is format for storing data. Similar to a Python dictionaries, it uses key value pairs. Dictionaries can be nested.\n",
    "\n",
    "**Which areas do the TIGER/Line shapefiles describe?**\n",
    "Shapefiles are available for the fifty states, District of Columbia, Puerto Rico, and the Island areas (American Samoa, the Commonwealth of the Northern\n",
    "Mariana Islands, Guam, and the United States Virgin Islands).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65508d3d-54ca-42c5-9bc1-08d0df1e790e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
